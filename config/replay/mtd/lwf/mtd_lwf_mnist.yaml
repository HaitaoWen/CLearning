# Dataset
dataset: MNIST
scenario: class
#order: none
init: 2
tasks: 5
# General setting
scheme: MTD
base: LwF
optim: SGD
lr: 0.01
lr_min: 1.0e-5
lr_patience: 6
decay: 0.
momentum: 0.9
gamma: 0.5
memory: 5
sample: random
bs: 10
epochs: 5

model: model.uncustomized.mlp.MLP
width: 100
depth: 2
input: 784
bias: false
batch_norm: false

# Hyperparameters
tau: 2
lambd: 1.0

finetune:
  blr: 0.001
  epochs: 15
  steps: [10]
  gamma: 0.1

mtd:
  num: 1
  tau: 2
  lambd: 1.0
  noise: 0.03
  dissimilar: 1.0
  permute: true  #true, false
  scale: false
  kl:
    p: 1.0
    c: 1.0
  output: average  # average, origin, max
  stages: ['layer1', 'fc']
#  dis_emb_avg: true

# Device
mode: GPU
gpuid: 0
workers: 4
seed: 1993
# Output
name: mtd/lwf/mnist/init2_5tasks
